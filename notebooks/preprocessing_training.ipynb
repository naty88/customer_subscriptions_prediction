{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53c9b6b3-4ea0-4797-af52-e14d35ca64dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 33\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[1;32m     31\u001B[0m get_ipython()\u001B[38;5;241m.\u001B[39mrun_line_magic(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmatplotlib\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minline\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 33\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m read_xlsx_file\n\u001B[1;32m     35\u001B[0m \u001B[38;5;66;03m# TODO:\u001B[39;00m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;66;03m# import black\u001B[39;00m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;66;03m# import jupyter_black\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;66;03m#     target_version=black.TargetVersion.PY310,\u001B[39;00m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;66;03m# )\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\") # go to parent dir\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Any\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, StratifiedKFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "from sklearn import metrics\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# classification algorithms \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import make_scorer, roc_auc_score, confusion_matrix,precision_score, recall_score, accuracy_score, balanced_accuracy_score, classification_report, precision_recall_curve, roc_curve,f1_score    \n",
    "\n",
    "import joblib\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from utils import read_xlsx_file\n",
    "\n",
    "# TODO:\n",
    "# import black\n",
    "# import jupyter_black\n",
    "# jupyter_black.load(\n",
    "#     lab=True,\n",
    "#     line_length=100,\n",
    "#     verbosity=\"INFO\",\n",
    "#     target_version=black.TargetVersion.PY310,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ff0b6e4-c121-4ce3-acab-bf3657e7a1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>wed</td>\n",
       "      <td>227</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>nov</td>\n",
       "      <td>wed</td>\n",
       "      <td>202</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>mon</td>\n",
       "      <td>1148</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>retired</td>\n",
       "      <td>divorced</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jun</td>\n",
       "      <td>tue</td>\n",
       "      <td>368</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job   marital          education  default housing loan  \\\n",
       "0   49   blue-collar   married           basic.9y  unknown      no   no   \n",
       "1   37  entrepreneur   married  university.degree       no      no   no   \n",
       "2   78       retired   married           basic.4y       no      no   no   \n",
       "3   36        admin.   married  university.degree       no     yes   no   \n",
       "4   59       retired  divorced  university.degree       no      no   no   \n",
       "\n",
       "     contact month day_of_week  duration  campaign  previous     poutcome    y  \n",
       "0   cellular   nov         wed       227         4         0  nonexistent   no  \n",
       "1  telephone   nov         wed       202         2         1      failure   no  \n",
       "2   cellular   jul         mon      1148         1         0  nonexistent  yes  \n",
       "3  telephone   may         mon       120         2         0  nonexistent   no  \n",
       "4   cellular   jun         tue       368         2         0  nonexistent   no  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data \n",
    "path_to_train_data = \"../data/train_file.xlsx\"\n",
    "df = read_xlsx_file(path_to_train_data)\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f03bd51-5736-45db-8b23-80f9f0c0bfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(keep=\"last\", inplace=True)  # remove duplicate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b18651-7392-408c-9035-9c5ec94db33a",
   "metadata": {},
   "source": [
    "#### Remove some features or their categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352af129-d417-4c77-965e-becf3c2abe66",
   "metadata": {},
   "source": [
    "The following *features* will be removed:\n",
    "* **duration**: This feature is highly correlated with the dependent variable \"y\". The data suggest that longer contact times are associated with a higher probability of subscribing to a fixed-term deposit. However, the duration of a contact is only known after the contact has been completed and the customer has made his decision. If we want to use this model for predictive inference in production, where predictions need to be made before the contact takes place, including \"duration\" as a feature is impractical. Therefore, this feature should be excluded from the training data to ensure that the model can be used effectively for real-time prediction.\n",
    "* **day_of_week**: EDA has shown that this feature does not have a significant impact on the customer\"s decision. Given its minimal impact, including it as a feature would not significantly improve the predictive performance of the model. Removing this feature from the training data helps to simplify the model and focus on more important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ae25cfc-e384-48c1-9085-861db18be9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_remove = [\"duration\", \"day_of_week\"]\n",
    "df_adjusted = df.drop(features_to_remove, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2ec091-5f6f-40a3-aa69-62530959fdba",
   "metadata": {},
   "source": [
    "**Dealing with unknown categories:** the *\"unknown\"* categories for such features, such as \"job\", \"education\", \"default\", \"housing\", \"loan\" will be removed, as they don\"t provide significant predictive value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c928fad4-457b-476a-9bf8-29a65a80ee37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adjusted = df_adjusted.query('job != \"unknown\" & education != \"unknown\" & default != \"unknown\" & housing != \"unknown\"')\n",
    "df_adjusted.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e838927-7894-49d2-a68c-9998642432db",
   "metadata": {},
   "source": [
    "**Combining basic education categories:** to simplify the dataset and improve model performance, all basic education categories (\"basic.4y\", \"basic.6y\", \"basic.9y\") are combined into a single, more general category \"education.basic\". This will reduce the complexity of the education feature and help the model to generalize better by treating all levels of basic education as equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0f61cd8-ca8e-43e8-9d35-e4bdd51b8d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>campaign</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15650</th>\n",
       "      <td>21245</td>\n",
       "      <td>31</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>single</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19463</th>\n",
       "      <td>26366</td>\n",
       "      <td>34</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3816</th>\n",
       "      <td>5196</td>\n",
       "      <td>34</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>nov</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  age         job  marital            education default housing  \\\n",
       "15650  21245   31   housemaid   single          high.school      no      no   \n",
       "19463  26366   34  technician   single  professional.course      no     yes   \n",
       "3816    5196   34  unemployed  married    university.degree      no     yes   \n",
       "\n",
       "      loan    contact month  campaign  previous     poutcome   y  \n",
       "15650  yes   cellular   jul         2         0  nonexistent  no  \n",
       "19463   no   cellular   may        11         0  nonexistent  no  \n",
       "3816    no  telephone   nov         1         0  nonexistent  no  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adjusted[\"education\"] = df_adjusted[\"education\"].replace([\"basic.4y\", \"basic.6y\", \"basic.9y\"], \"education.basic\")\n",
    "df_adjusted.sample(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86b7c53-81a2-43a5-8729-58e214ba861f",
   "metadata": {},
   "source": [
    "**Binning age:** given the wide distribution of ages in the dataset, we will split this category into four quantile-based bins. This approach will group the ages into four equally sized bins, which will help to normalize the distribution and potentially improve the performance of the model by reducing the effect of outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88bd058e-3469-4a61-9fe5-1b50cabd49fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_nmb = 5\n",
    "age_order = [\"young\", \"young_adult\", \"middle_aged\", \"late_middle_aged\", \"middle_old_age\"]\n",
    "bins_age = pd.cut(df_adjusted[\"age\"], bins=bins_nmb, labels=age_order)\n",
    "df_adjusted.insert(1, \"bins_age\", bins_age) # Min/Max in each bin: [(16.926, 31.8] < (31.8, 46.6] < (46.6, 61.4] < (61.4, 76.2] < (76.2, 91.0]]\n",
    "# remove age column from dataframe\n",
    "df_adjusted.drop(\"age\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e91ba10-ada4-49d8-b74c-7b6583586538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins_age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b421119b-2635-46b8-aa7b-db8235fad732",
   "metadata": {},
   "source": [
    "#### Pipeline definition with encoding and scaling categorical and numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51e68634-2bc1-4dc8-9ff7-e1b484b473fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding with LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df_adjusted[\"contact\"] = label_encoder.fit_transform(df_adjusted[\"contact\"])\n",
    "\n",
    "# encoding with binary values\n",
    "binary_mapping = {\"yes\": 1, \"no\": 0}\n",
    "columns_to_map = [\"default\", \"loan\", \"housing\", \"y\"]\n",
    "for column in columns_to_map:\n",
    "    df_adjusted[column] = df_adjusted[column].map(binary_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae02e4e5-9b57-4e94-8a01-26fb30642f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>bins_age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>campaign</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>young_adult</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>nov</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>middle_old_age</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>education.basic</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>jul</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>young_adult</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>may</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>middle_aged</td>\n",
       "      <td>retired</td>\n",
       "      <td>divorced</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>jun</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>young</td>\n",
       "      <td>admin.</td>\n",
       "      <td>single</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>aug</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        bins_age           job   marital          education  default  \\\n",
       "0      1     young_adult  entrepreneur   married  university.degree        0   \n",
       "1      2  middle_old_age       retired   married    education.basic        0   \n",
       "2      3     young_adult        admin.   married  university.degree        0   \n",
       "3      4     middle_aged       retired  divorced  university.degree        0   \n",
       "4      5           young        admin.    single  university.degree        0   \n",
       "\n",
       "   housing  loan  contact month  campaign  previous     poutcome  y  \n",
       "0        0     0        1   nov         2         1      failure  0  \n",
       "1        0     0        0   jul         1         0  nonexistent  1  \n",
       "2        1     0        1   may         2         0  nonexistent  0  \n",
       "3        0     0        0   jun         2         0  nonexistent  0  \n",
       "4        0     0        0   aug         2         0  nonexistent  0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adjusted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "326a8651-9a99-4b94-9395-76c9cdb8fdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hierarchical order for some ordinal features\n",
    "education_order = [\"illiterate\", \"education.basic\", \"high.school\", \"professional.course\", \"university.degree\"]\n",
    "month_order = [\"jan\", \"feb\", \"mar\", \"apr\", \"may\", \"jun\", \"jul\", \"aug\", \"sep\", \"oct\", \"nov\", \"dec\"]\n",
    "poutcome_order = [\"nonexistent\", \"failure\", \"success\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b366ebb7-13fd-45d0-933f-bf6c706b9a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # ordinal encoding\n",
    "        (\"bins_age_enc\", Pipeline(steps=[\n",
    "            ('ordinal', OrdinalEncoder(categories=[age_order])),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), ['bins_age']),\n",
    "        (\"education\", Pipeline(steps=[\n",
    "            ('ordinal', OrdinalEncoder(categories=[education_order])),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), ['education']),\n",
    "        (\"month\", Pipeline(steps=[\n",
    "            ('ordinal', OrdinalEncoder(categories=[month_order])),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), ['month']),\n",
    "        (\"poutcome\", Pipeline(steps=[\n",
    "            ('ordinal', OrdinalEncoder(categories=[poutcome_order])),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), ['poutcome']),\n",
    "        \n",
    "        # LabelEncoder was applied separately\n",
    "        (\"contact\", \"passthrough\", [\"contact\"]),\n",
    "        \n",
    "        # binary encoding was applied separately\n",
    "        (\"binary\", \"passthrough\", [\"default\", \"loan\", \"housing\"]),\n",
    "        \n",
    "        # One-Hot encoding for job and marital\n",
    "        (\"job_marital\", OneHotEncoder(), [\"job\", \"marital\"]),\n",
    "        \n",
    "        # Standard scaling of the rest numeric features\n",
    "        (\"scaling\", StandardScaler(), [\"previous\", \"campaign\"])\n",
    "    ],\n",
    "    remainder=\"passthrough\"  # leave the other columns unchanged\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a4b4fed-107a-4177-b2af-f43bc43ad55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X = df_adjusted.drop(\"y\", axis=1)\n",
    "y = df_adjusted[\"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5b5764-a606-471c-9e4a-6c1cd2bb60f9",
   "metadata": {},
   "source": [
    "#### Data splitting and balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdbdd08e-b48f-4c12-875f-f33d664e6897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (21882, 13) --- (21882,)\n",
      "Testing set shape: (2432, 13) --- (2432,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "print(f\"Training set shape: {X_train.shape} --- {y_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape} --- {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f58ff25-132e-44a3-9f57-5e027cc81ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d940663-d22a-4c8b-a43c-69eea9538788",
   "metadata": {},
   "source": [
    "#### Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aaa09a24-deb5-4909-926b-30e738cb329d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the models\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(solver=\"liblinear\", max_iter=1000),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "    \"RandomForest\": RandomForestClassifier(),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(),\n",
    "    \"SVC\": SVC(),\n",
    "    \"KNN\": KNeighborsClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e34610-9a5e-4e29-b3ed-d0ed1512437c",
   "metadata": {},
   "source": [
    "##### Model evaluation using cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "171a49b8-f4ec-4c7f-a6e9-2128e5a7cbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_conf_mtx(y_gold, y_pred, model_name):\n",
    "    conf_mtx = confusion_matrix(y_gold, y_pred)\n",
    "    plt.figure(figsize=(4, 2))\n",
    "    sns.heatmap(conf_mtx, annot=True, cmap=\"Blues\", fmt='d', cbar=False, annot_kws={\"fontsize\":8})\n",
    "    plt.title(f'{model_name}', fontsize=10, pad=10)\n",
    "    plt.xlabel('Predicted', fontsize=8)\n",
    "    plt.ylabel('True', fontsize=8)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf179b5d-a8bb-41ef-a6cb-ea10369436bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models evaluation using cross-validation\n",
    "def get_mean_val(scores_dict: Dict[str, np.ndarray], val_name: str):\n",
    "    if val_name not in scores_dict:\n",
    "        raise KeyError(f\"{val_name} is not found in the scores dictionary.\")\n",
    "    return scores_dict[val_name].mean()\n",
    "    \n",
    "results = {}\n",
    "skf = StratifiedKFold(n_splits=5) # StratifiedKFold is used by default for classification tasks\n",
    "\n",
    "metrics = [\n",
    "    'accuracy',\n",
    "    'f1',\n",
    "    \"roc_auc\"]\n",
    "\n",
    "# for model_name, model in models.items():    \n",
    "#     pipeline = ImbPipeline(steps=[\n",
    "#         ('preprocessor', preprocessor),\n",
    "#         ('smote', SMOTE()),  # since the data is very imbalanced, it's better to balance them\n",
    "#         ('classifier', model)\n",
    "#     ])\n",
    "\n",
    "#     cv_scores_dict = {}\n",
    "#     cv_scores = cross_validate(pipeline, X_train, y_train, cv=skf, scoring=metrics)\n",
    "#     results[model_name] = {\"fit_time_mean\": get_mean_val(cv_scores, \"fit_time\"),\n",
    "#                            \"accuracy_mean\": get_mean_val(cv_scores, \"test_accuracy\"),\n",
    "#                            \"f1_mean\": get_mean_val(cv_scores, \"test_f1\"),\n",
    "#                            \"roc_auc_mean\": get_mean_val(cv_scores, \"test_roc_auc\")\n",
    "#                           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fcc3a3f-bbcd-402e-a447-f3309099366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "630ccea9-88c0-4d3d-a7ea-683cdfab0f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # best model based on F1 score\n",
    "# best_model_name = max(results, key=lambda model: results[model][\"accuracy_mean\"])\n",
    "# best_model_name "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae63308d-1769-4a84-b366-8e4f87c37cca",
   "metadata": {},
   "source": [
    "##### Train the best model on the full training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ef07ab4-4808-4063-bc27-38ea31c88f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline = ImbPipeline(steps=[\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('smote', SMOTE()),\n",
    "#     ('classifier', models[best_model_name])\n",
    "# ])\n",
    "# pipeline.fit(X_train, y_train)\n",
    "\n",
    "# # model evaluation on the test date\n",
    "# y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1628f3d-a6a5-4de2-9e41-b2b0f63e2d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### TODO: remove\n",
    "best_model_name = \"GradientBoosting\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1376fe55-db05-444d-a70a-dc99a914d227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     'learning_rate': trial.suggest_float('learning_rate', 0.08, 1.0),\n",
    "#     'n_estimators': trial.suggest_int('n_estimators', 300, 500),\n",
    "#     'max_depth':trial.suggest_int('max_depth', 3, 7),\n",
    "#     'max_features': trial.suggest_int('max_features', 5, 15),\n",
    "#     'min_samples_split': trial.suggest_int('min_samples_split', 2, 50),\n",
    "#     'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n",
    "#     'random_state': 42\n",
    "#   }\n",
    "\n",
    "# feature_name = \"min_samples_split\"\n",
    "\n",
    "\n",
    "# train_results = []\n",
    "# test_results = []\n",
    "# for min_samples_split in min_samples_split_l:\n",
    "#     model = GradientBoostingClassifier(learning_rate=1.0,\n",
    "#                                        n_estimators=500,\n",
    "#                                        max_depth=6,\n",
    "#                                        max_features=15,\n",
    "#                                       )\n",
    "#     # Define the pipeline with SMOTE and the preprocessor\n",
    "#     pipeline = ImbPipeline(steps=[\n",
    "#         ('preprocessor', preprocessor),\n",
    "#         ('smote', SMOTE()),\n",
    "#         ('classifier', model)\n",
    "#         ])\n",
    "    \n",
    "#     pipeline.fit(X_train, y_train)\n",
    "#     train_pred = pipeline.predict(X_train)\n",
    "#     roc_auc = roc_auc_score(y_train, train_pred)\n",
    "#     train_results.append(roc_auc)\n",
    "    \n",
    "#     y_pred = pipeline.predict(X_test)\n",
    "#     roc_auc = roc_auc_score(y_test, y_pred)\n",
    "#     test_results.append(roc_auc)\n",
    "\n",
    "# from matplotlib.legend_handler import HandlerLine2D\n",
    "# line1, = plt.plot(max_features_l, train_results, 'b', label=\"Train AUC\")\n",
    "# line2, = plt.plot(max_features_l, test_results, 'r', label=\"Test AUC\")\n",
    "# plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "# plt.ylabel('AUC score')\n",
    "# plt.xlabel(feature_name)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccccfad-5b11-48c8-9246-fadc75763c69",
   "metadata": {},
   "source": [
    "##### Hyperparameter tuning of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ffeecda-01a2-464b-8759-49b0cf243f18",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trial' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 8\u001B[0m\n\u001B[1;32m      3\u001B[0m max_depth_values \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m2\u001B[39m]  \u001B[38;5;66;03m# how deep the built tree can be\u001B[39;00m\n\u001B[1;32m      4\u001B[0m n_estimators_values \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m90\u001B[39m, \u001B[38;5;241m100\u001B[39m]  \u001B[38;5;66;03m# the number of trees in the forest\u001B[39;00m\n\u001B[1;32m      6\u001B[0m models_params \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLogisticRegression\u001B[39m\u001B[38;5;124m\"\u001B[39m:  {\n\u001B[0;32m----> 8\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mC\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[43mtrial\u001B[49m\u001B[38;5;241m.\u001B[39msuggest_float(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mC\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m0.01\u001B[39m, \u001B[38;5;241m0.1\u001B[39m), \u001B[38;5;66;03m# Regularization parameter, controlling the trade-off between maximizing the margin and minimizing classification error\u001B[39;00m\n\u001B[1;32m      9\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msolver\u001B[39m\u001B[38;5;124m'\u001B[39m: trial\u001B[38;5;241m.\u001B[39msuggest_categorical(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msolver\u001B[39m\u001B[38;5;124m'\u001B[39m, [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mliblinear\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnewton-cholesky\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m     10\u001B[0m     },\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDecisionTreeClassifier\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[1;32m     12\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msplitter\u001B[39m\u001B[38;5;124m'\u001B[39m: trial\u001B[38;5;241m.\u001B[39msuggest_categorical(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msplitter\u001B[39m\u001B[38;5;124m'\u001B[39m, [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbest\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrandom\u001B[39m\u001B[38;5;124m\"\u001B[39m]),\n\u001B[1;32m     13\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_depth\u001B[39m\u001B[38;5;124m'\u001B[39m: trial\u001B[38;5;241m.\u001B[39msuggest_int(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_depth\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m4\u001B[39m),\n\u001B[1;32m     14\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclass_weight\u001B[39m\u001B[38;5;124m'\u001B[39m: trial\u001B[38;5;241m.\u001B[39msuggest_categorical(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclass_weight\u001B[39m\u001B[38;5;124m'\u001B[39m, [\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbalanced\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m     15\u001B[0m     },\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRandomForest\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[1;32m     17\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mn_estimators\u001B[39m\u001B[38;5;124m'\u001B[39m: trial\u001B[38;5;241m.\u001B[39msuggest_int(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mn_estimators\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m100\u001B[39m, \u001B[38;5;241m500\u001B[39m),\n\u001B[1;32m     18\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_depth\u001B[39m\u001B[38;5;124m'\u001B[39m: trial\u001B[38;5;241m.\u001B[39msuggest_int(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_depth\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m4\u001B[39m),\n\u001B[1;32m     19\u001B[0m     },\n\u001B[1;32m     20\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGradientBoosting\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[1;32m     21\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlearning_rate\u001B[39m\u001B[38;5;124m'\u001B[39m: trial\u001B[38;5;241m.\u001B[39msuggest_float(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlearning_rate\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m0.08\u001B[39m, \u001B[38;5;241m1.0\u001B[39m),\n\u001B[1;32m     22\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mn_estimators\u001B[39m\u001B[38;5;124m'\u001B[39m: trial\u001B[38;5;241m.\u001B[39msuggest_int(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mn_estimators\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m100\u001B[39m, \u001B[38;5;241m500\u001B[39m),\n\u001B[1;32m     23\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrandom_state\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m42\u001B[39m\n\u001B[1;32m     24\u001B[0m     },\n\u001B[1;32m     25\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSVC\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[1;32m     26\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mC\u001B[39m\u001B[38;5;124m'\u001B[39m: trial\u001B[38;5;241m.\u001B[39msuggest_float(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mC\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m0.1\u001B[39m, \u001B[38;5;241m1.5\u001B[39m),\n\u001B[1;32m     27\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgamma\u001B[39m\u001B[38;5;124m'\u001B[39m: trial\u001B[38;5;241m.\u001B[39msuggest_categorical(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgamma\u001B[39m\u001B[38;5;124m'\u001B[39m, [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscale\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m\"\u001B[39m]),\n\u001B[1;32m     28\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mkernel\u001B[39m\u001B[38;5;124m'\u001B[39m:  trial\u001B[38;5;241m.\u001B[39msuggest_categorical(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mkernel\u001B[39m\u001B[38;5;124m'\u001B[39m, [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlinear\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpoly\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrbf\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m     29\u001B[0m     },\n\u001B[1;32m     30\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mKNN\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[1;32m     31\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mn_neighbors\u001B[39m\u001B[38;5;124m'\u001B[39m: trial\u001B[38;5;241m.\u001B[39msuggest_int(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mn_neighbors\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m19\u001B[39m),\n\u001B[1;32m     32\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mweights\u001B[39m\u001B[38;5;124m'\u001B[39m: trial\u001B[38;5;241m.\u001B[39msuggest_categorical(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mweights\u001B[39m\u001B[38;5;124m'\u001B[39m, [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124muniform\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdistance\u001B[39m\u001B[38;5;124m'\u001B[39m]),\n\u001B[1;32m     33\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmetric\u001B[39m\u001B[38;5;124m'\u001B[39m: trial\u001B[38;5;241m.\u001B[39msuggest_categorical(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmetric\u001B[39m\u001B[38;5;124m'\u001B[39m, [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ml2\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmanhattan\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcosine\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     34\u001B[0m     }\n\u001B[1;32m     35\u001B[0m }\n",
      "\u001B[0;31mNameError\u001B[0m: name 'trial' is not defined"
     ]
    }
   ],
   "source": [
    "# predifine a set of hyperparameters for the models\n",
    "models_params = {\n",
    "    \"LogisticRegression\":  {\n",
    "        'C': trial.suggest_float('C', 0.01, 0.1), # Regularization parameter, controlling the trade-off between maximizing the margin and minimizing classification error\n",
    "        'solver': trial.suggest_categorical('solver', [\"liblinear\", \"newton-cholesky\"])\n",
    "    },\n",
    "    \"DecisionTreeClassifier\": {\n",
    "        'splitter': trial.suggest_categorical('splitter', [\"best\", \"random\"]),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 4),\n",
    "        'class_weight': trial.suggest_categorical('class_weight', [None, \"balanced\"])\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 4),\n",
    "    },\n",
    "    \"GradientBoosting\": {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.08, 1.0),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'random_state': 42\n",
    "    },\n",
    "    \"SVC\": {\n",
    "        'C': trial.suggest_float('C', 0.1, 1.5),\n",
    "        'gamma': trial.suggest_categorical('gamma', [\"scale\", \"auto\"]),\n",
    "        'kernel':  trial.suggest_categorical('kernel', [\"linear\", \"poly\", \"rbf\"])\n",
    "    },\n",
    "    \"KNN\": {\n",
    "        'n_neighbors': trial.suggest_int('n_neighbors', 2, 19),\n",
    "        'weights': trial.suggest_categorical('weights', ['uniform', 'distance']),\n",
    "        'metric': trial.suggest_categorical('metric', ['l2', 'manhattan', 'cosine'])\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477ac655-781c-4319-b4ba-fd3dcc01bc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nataliia/Workspaces/edu_private/user_behaviour_prediction/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2024-06-03 16:39:10,583] A new study created in RDB with name: no-name-2680ea83-ac70-4759-9f58-9d3a066e5f66\n",
      "[I 2024-06-03 16:39:25,415] Trial 0 finished with value: 0.31204701246073996 and parameters: {'learning_rate': 0.33362967435484786, 'n_estimators': 165}. Best is trial 0 with value: 0.31204701246073996.\n",
      "[I 2024-06-03 16:39:47,637] Trial 1 finished with value: 0.3035797206166133 and parameters: {'learning_rate': 0.1462565578756947, 'n_estimators': 271}. Best is trial 0 with value: 0.31204701246073996.\n",
      "[I 2024-06-03 16:40:24,550] Trial 2 finished with value: 0.30862796972569456 and parameters: {'learning_rate': 0.6166439999659143, 'n_estimators': 448}. Best is trial 0 with value: 0.31204701246073996.\n",
      "[I 2024-06-03 16:40:33,779] Trial 3 finished with value: 0.30667817241357087 and parameters: {'learning_rate': 0.38532553764890204, 'n_estimators': 103}. Best is trial 0 with value: 0.31204701246073996.\n",
      "[I 2024-06-03 16:40:45,676] Trial 4 finished with value: 0.31408960374411227 and parameters: {'learning_rate': 0.7075308287101091, 'n_estimators': 143}. Best is trial 4 with value: 0.31408960374411227.\n",
      "[I 2024-06-03 16:41:23,228] Trial 5 pruned. \n",
      "[I 2024-06-03 16:41:34,345] Trial 6 pruned. \n",
      "[I 2024-06-03 16:41:54,158] Trial 7 pruned. \n",
      "[I 2024-06-03 16:42:21,667] Trial 8 pruned. \n",
      "[I 2024-06-03 16:42:37,881] Trial 9 pruned. \n",
      "[I 2024-06-03 16:43:05,797] Trial 10 finished with value: 0.31168593598070116 and parameters: {'learning_rate': 0.7007766887851331, 'n_estimators': 330}. Best is trial 4 with value: 0.31408960374411227.\n",
      "[I 2024-06-03 16:43:21,093] Trial 11 finished with value: 0.3126230613083066 and parameters: {'learning_rate': 0.8146906862963601, 'n_estimators': 179}. Best is trial 4 with value: 0.31408960374411227.\n",
      "[I 2024-06-03 16:43:36,891] Trial 12 finished with value: 0.31253492326733934 and parameters: {'learning_rate': 0.8444903414299676, 'n_estimators': 194}. Best is trial 4 with value: 0.31408960374411227.\n",
      "[I 2024-06-03 16:43:49,565] Trial 13 finished with value: 0.31569643704749967 and parameters: {'learning_rate': 0.7390686509077871, 'n_estimators': 151}. Best is trial 13 with value: 0.31569643704749967.\n",
      "[I 2024-06-03 16:44:21,182] Trial 14 finished with value: 0.313321243982464 and parameters: {'learning_rate': 0.6409576620147143, 'n_estimators': 385}. Best is trial 13 with value: 0.31569643704749967.\n",
      "[I 2024-06-03 16:44:39,701] Trial 15 pruned. \n",
      "[I 2024-06-03 16:44:50,093] Trial 16 pruned. \n",
      "[I 2024-06-03 16:45:02,426] Trial 17 finished with value: 0.31252566256620473 and parameters: {'learning_rate': 0.5586592407309565, 'n_estimators': 149}. Best is trial 13 with value: 0.31569643704749967.\n",
      "[I 2024-06-03 16:45:24,718] Trial 18 pruned. \n",
      "[I 2024-06-03 16:45:42,112] Trial 19 pruned. \n",
      "[I 2024-06-03 16:45:49,953] Trial 20 pruned. \n",
      "[I 2024-06-03 16:46:22,592] Trial 21 finished with value: 0.31616692156298926 and parameters: {'learning_rate': 0.5899372424970257, 'n_estimators': 415}. Best is trial 21 with value: 0.31616692156298926.\n",
      "[I 2024-06-03 16:46:55,264] Trial 22 pruned. \n",
      "[I 2024-06-03 16:47:20,500] Trial 23 finished with value: 0.3150035757997157 and parameters: {'learning_rate': 0.7346027396796692, 'n_estimators': 313}. Best is trial 21 with value: 0.31616692156298926.\n",
      "[I 2024-06-03 16:47:44,843] Trial 24 pruned. \n",
      "[I 2024-06-03 16:48:14,750] Trial 25 finished with value: 0.31543763020811966 and parameters: {'learning_rate': 0.7854837647073104, 'n_estimators': 375}. Best is trial 21 with value: 0.31616692156298926.\n",
      "[I 2024-06-03 16:48:44,464] Trial 26 pruned. \n",
      "[I 2024-06-03 16:49:22,150] Trial 27 pruned. \n",
      "[I 2024-06-03 16:49:54,228] Trial 28 pruned. \n",
      "[I 2024-06-03 16:50:27,864] Trial 29 pruned. \n",
      "[I 2024-06-03 16:50:54,807] Trial 30 pruned. \n",
      "[I 2024-06-03 16:51:17,706] Trial 31 finished with value: 0.3137999202187597 and parameters: {'learning_rate': 0.7357955128330693, 'n_estimators': 302}. Best is trial 21 with value: 0.31616692156298926.\n",
      "[I 2024-06-03 16:51:47,585] Trial 32 pruned. \n",
      "[I 2024-06-03 16:52:15,268] Trial 33 finished with value: 0.31644152464315073 and parameters: {'learning_rate': 0.7716750562435241, 'n_estimators': 350}. Best is trial 33 with value: 0.31644152464315073.\n",
      "[I 2024-06-03 16:52:42,587] Trial 34 pruned. \n",
      "[I 2024-06-03 16:53:18,858] Trial 35 pruned. \n",
      "[I 2024-06-03 16:53:41,579] Trial 36 finished with value: 0.31774572748698937 and parameters: {'learning_rate': 0.76722860813933, 'n_estimators': 280}. Best is trial 36 with value: 0.31774572748698937.\n",
      "[I 2024-06-03 16:54:05,888] Trial 37 pruned. \n",
      "[I 2024-06-03 16:54:25,569] Trial 38 pruned. \n",
      "[I 2024-06-03 16:55:04,787] Trial 39 pruned. \n",
      "[I 2024-06-03 16:55:25,931] Trial 40 pruned. \n",
      "[I 2024-06-03 16:55:59,088] Trial 41 pruned. \n",
      "[I 2024-06-03 16:56:29,502] Trial 42 pruned. \n",
      "[I 2024-06-03 16:57:04,132] Trial 43 pruned. \n",
      "[I 2024-06-03 16:57:31,086] Trial 44 pruned. \n",
      "[I 2024-06-03 16:57:59,326] Trial 45 pruned. \n",
      "[I 2024-06-03 16:58:35,460] Trial 46 pruned. \n",
      "[I 2024-06-03 16:59:06,427] Trial 47 pruned. \n",
      "[I 2024-06-03 16:59:23,435] Trial 48 pruned. \n",
      "[I 2024-06-03 16:59:37,027] Trial 49 pruned. \n",
      "[I 2024-06-03 17:00:02,144] Trial 50 pruned. \n",
      "[I 2024-06-03 17:00:27,012] Trial 51 pruned. \n",
      "[I 2024-06-03 17:00:50,235] Trial 52 pruned. \n",
      "[I 2024-06-03 17:01:18,817] Trial 53 finished with value: 0.3139385600952608 and parameters: {'learning_rate': 0.6121826437228922, 'n_estimators': 364}. Best is trial 36 with value: 0.31774572748698937.\n",
      "[I 2024-06-03 17:01:45,106] Trial 54 pruned. \n",
      "[I 2024-06-03 17:01:54,897] Trial 55 pruned. \n",
      "[I 2024-06-03 17:02:07,405] Trial 56 pruned. \n",
      "[I 2024-06-03 17:02:31,516] Trial 57 pruned. \n",
      "[I 2024-06-03 17:03:03,816] Trial 58 pruned. \n",
      "[I 2024-06-03 17:03:39,116] Trial 59 pruned. \n",
      "[I 2024-06-03 17:04:18,183] Trial 60 pruned. \n",
      "[I 2024-06-03 17:04:30,984] Trial 61 pruned. \n",
      "[I 2024-06-03 17:04:46,619] Trial 62 pruned. \n",
      "[I 2024-06-03 17:04:56,040] Trial 63 pruned. \n",
      "[I 2024-06-03 17:05:10,152] Trial 64 pruned. \n",
      "[I 2024-06-03 17:05:31,036] Trial 65 pruned. \n",
      "[I 2024-06-03 17:05:42,613] Trial 66 pruned. \n",
      "[I 2024-06-03 17:05:58,036] Trial 67 pruned. \n",
      "[I 2024-06-03 17:06:28,781] Trial 68 finished with value: 0.31430808624449724 and parameters: {'learning_rate': 0.8372413115083438, 'n_estimators': 384}. Best is trial 36 with value: 0.31774572748698937.\n",
      "[I 2024-06-03 17:06:59,033] Trial 69 pruned. \n",
      "[I 2024-06-03 17:07:30,977] Trial 70 pruned. \n",
      "[I 2024-06-03 17:07:59,660] Trial 71 finished with value: 0.31778004237134255 and parameters: {'learning_rate': 0.8616286682279518, 'n_estimators': 355}. Best is trial 71 with value: 0.31778004237134255.\n",
      "[I 2024-06-03 17:08:27,314] Trial 72 finished with value: 0.3188490709655847 and parameters: {'learning_rate': 0.9846405133006645, 'n_estimators': 353}. Best is trial 72 with value: 0.3188490709655847.\n",
      "[I 2024-06-03 17:08:55,606] Trial 73 pruned. \n",
      "[I 2024-06-03 17:09:24,962] Trial 74 pruned. \n",
      "[I 2024-06-03 17:09:50,054] Trial 75 finished with value: 0.3157646591223443 and parameters: {'learning_rate': 0.8761893901135, 'n_estimators': 320}. Best is trial 72 with value: 0.3188490709655847.\n",
      "[I 2024-06-03 17:10:17,003] Trial 76 pruned. \n",
      "[I 2024-06-03 17:10:47,045] Trial 77 pruned. \n",
      "[I 2024-06-03 17:11:10,408] Trial 78 pruned. \n",
      "[I 2024-06-03 17:11:40,568] Trial 79 finished with value: 0.3147287703835485 and parameters: {'learning_rate': 0.8599190657487672, 'n_estimators': 376}. Best is trial 72 with value: 0.3188490709655847.\n",
      "[I 2024-06-03 17:12:06,906] Trial 80 pruned. \n",
      "[I 2024-06-03 17:12:31,954] Trial 81 finished with value: 0.3148197933251565 and parameters: {'learning_rate': 0.8047304372093236, 'n_estimators': 321}. Best is trial 72 with value: 0.3188490709655847.\n",
      "[I 2024-06-03 17:12:59,577] Trial 82 pruned. \n",
      "[I 2024-06-03 17:13:25,729] Trial 83 pruned. \n",
      "[I 2024-06-03 17:13:47,154] Trial 84 pruned. \n",
      "[I 2024-06-03 17:14:22,331] Trial 85 finished with value: 0.315294850122377 and parameters: {'learning_rate': 0.8908410966652673, 'n_estimators': 420}. Best is trial 72 with value: 0.3188490709655847.\n",
      "[I 2024-06-03 17:14:55,784] Trial 86 pruned. \n",
      "[I 2024-06-03 17:15:26,659] Trial 87 finished with value: 0.3146737243352823 and parameters: {'learning_rate': 0.898782922562213, 'n_estimators': 395}. Best is trial 72 with value: 0.3188490709655847.\n",
      "[I 2024-06-03 17:16:03,498] Trial 88 pruned. \n",
      "[I 2024-06-03 17:16:37,082] Trial 89 pruned. \n",
      "[I 2024-06-03 17:17:12,132] Trial 90 pruned. \n",
      "[I 2024-06-03 17:17:41,343] Trial 91 finished with value: 0.3181317051018988 and parameters: {'learning_rate': 0.7779487375496903, 'n_estimators': 372}. Best is trial 72 with value: 0.3188490709655847.\n",
      "[I 2024-06-03 17:18:11,247] Trial 92 pruned. \n",
      "[I 2024-06-03 17:18:41,774] Trial 93 pruned. \n",
      "[I 2024-06-03 17:19:12,510] Trial 94 pruned. \n",
      "[I 2024-06-03 17:19:45,610] Trial 95 pruned. \n",
      "[I 2024-06-03 17:20:11,715] Trial 96 pruned. \n",
      "[I 2024-06-03 17:20:44,721] Trial 97 pruned. \n",
      "[I 2024-06-03 17:21:13,622] Trial 98 pruned. \n",
      "[I 2024-06-03 17:21:31,875] Trial 99 pruned. \n",
      "[I 2024-06-03 17:21:59,553] Trial 100 pruned. \n",
      "[I 2024-06-03 17:22:25,038] Trial 101 pruned. \n",
      "[I 2024-06-03 17:22:46,975] Trial 102 pruned. \n",
      "[I 2024-06-03 17:23:11,443] Trial 103 pruned. \n",
      "[I 2024-06-03 17:23:39,389] Trial 104 pruned. \n",
      "[I 2024-06-03 17:24:12,859] Trial 105 pruned. \n",
      "[I 2024-06-03 17:24:42,479] Trial 106 pruned. \n",
      "[I 2024-06-03 17:25:11,952] Trial 107 pruned. \n",
      "[I 2024-06-03 17:25:48,608] Trial 108 pruned. \n",
      "[I 2024-06-03 17:26:14,485] Trial 109 pruned. \n",
      "[I 2024-06-03 17:26:44,003] Trial 110 pruned. \n",
      "[I 2024-06-03 17:27:10,694] Trial 111 finished with value: 0.32029736654408136 and parameters: {'learning_rate': 0.8126795257645933, 'n_estimators': 331}. Best is trial 111 with value: 0.32029736654408136.\n",
      "[I 2024-06-03 17:27:34,075] Trial 112 finished with value: 0.3230262831838028 and parameters: {'learning_rate': 0.8093669054197972, 'n_estimators': 293}. Best is trial 112 with value: 0.3230262831838028.\n",
      "[I 2024-06-03 17:27:58,809] Trial 113 pruned. \n",
      "[I 2024-06-03 17:28:26,382] Trial 114 pruned. \n",
      "[I 2024-06-03 17:28:47,877] Trial 115 pruned. \n",
      "[I 2024-06-03 17:29:14,096] Trial 116 pruned. \n",
      "[I 2024-06-03 17:29:41,470] Trial 117 finished with value: 0.3159532636529444 and parameters: {'learning_rate': 0.8324303173550464, 'n_estimators': 348}. Best is trial 112 with value: 0.3230262831838028.\n",
      "[I 2024-06-03 17:30:08,869] Trial 118 pruned. \n",
      "[I 2024-06-03 17:30:35,347] Trial 119 pruned. \n",
      "[I 2024-06-03 17:31:06,126] Trial 120 pruned. \n",
      "[I 2024-06-03 17:31:38,866] Trial 121 finished with value: 0.31626006216943325 and parameters: {'learning_rate': 0.8507618786415861, 'n_estimators': 411}. Best is trial 112 with value: 0.3230262831838028.\n",
      "[I 2024-06-03 17:32:08,473] Trial 122 finished with value: 0.31520133622911195 and parameters: {'learning_rate': 0.8466496789696576, 'n_estimators': 380}. Best is trial 112 with value: 0.3230262831838028.\n",
      "[I 2024-06-03 17:32:38,690] Trial 123 finished with value: 0.32374222378531436 and parameters: {'learning_rate': 0.8100137615841516, 'n_estimators': 401}. Best is trial 123 with value: 0.32374222378531436.\n",
      "[I 2024-06-03 17:33:09,371] Trial 124 pruned. \n",
      "[I 2024-06-03 17:33:33,759] Trial 125 pruned. \n",
      "[I 2024-06-03 17:34:00,218] Trial 126 pruned. \n",
      "[I 2024-06-03 17:34:31,630] Trial 127 pruned. \n",
      "[I 2024-06-03 17:35:00,458] Trial 128 pruned. \n",
      "[I 2024-06-03 17:35:31,992] Trial 129 finished with value: 0.31587660914078286 and parameters: {'learning_rate': 0.43208306858790013, 'n_estimators': 398}. Best is trial 123 with value: 0.32374222378531436.\n",
      "[I 2024-06-03 17:36:03,710] Trial 130 pruned. \n",
      "[I 2024-06-03 17:36:35,930] Trial 131 pruned. \n",
      "[I 2024-06-03 17:36:55,710] Trial 132 pruned. \n",
      "[I 2024-06-03 17:37:30,897] Trial 133 pruned. \n",
      "[I 2024-06-03 17:38:06,026] Trial 134 pruned. \n",
      "[I 2024-06-03 17:38:38,133] Trial 135 pruned. \n",
      "[I 2024-06-03 17:39:07,480] Trial 136 pruned. \n",
      "[I 2024-06-03 17:39:35,172] Trial 137 pruned. \n",
      "[I 2024-06-03 17:39:47,955] Trial 138 pruned. \n",
      "[I 2024-06-03 17:39:57,378] Trial 139 pruned. \n",
      "[I 2024-06-03 17:40:18,429] Trial 140 finished with value: 0.31724436450773086 and parameters: {'learning_rate': 0.7747164064964063, 'n_estimators': 266}. Best is trial 123 with value: 0.32374222378531436.\n",
      "[I 2024-06-03 17:40:38,852] Trial 141 finished with value: 0.31702535989063835 and parameters: {'learning_rate': 0.7806785637019507, 'n_estimators': 254}. Best is trial 123 with value: 0.32374222378531436.\n",
      "[I 2024-06-03 17:40:58,745] Trial 142 pruned. \n",
      "[I 2024-06-03 17:41:19,536] Trial 143 finished with value: 0.31538210236620856 and parameters: {'learning_rate': 0.8215060721228475, 'n_estimators': 258}. Best is trial 123 with value: 0.32374222378531436.\n",
      "[I 2024-06-03 17:41:41,518] Trial 144 pruned. \n",
      "[I 2024-06-03 17:42:05,571] Trial 145 pruned. \n",
      "[I 2024-06-03 17:42:26,975] Trial 146 pruned. \n",
      "[I 2024-06-03 17:42:50,245] Trial 147 pruned. \n",
      "[I 2024-06-03 17:43:13,057] Trial 148 pruned. \n",
      "[I 2024-06-03 17:43:34,334] Trial 149 pruned. \n",
      "[I 2024-06-03 17:43:57,889] Trial 150 finished with value: 0.3175458158713305 and parameters: {'learning_rate': 0.7430101649009296, 'n_estimators': 300}. Best is trial 123 with value: 0.32374222378531436.\n",
      "[I 2024-06-03 17:44:22,040] Trial 151 pruned. \n",
      "[I 2024-06-03 17:44:44,210] Trial 152 pruned. \n",
      "[I 2024-06-03 17:45:05,697] Trial 153 pruned. \n",
      "[I 2024-06-03 17:45:30,810] Trial 154 pruned. \n",
      "[I 2024-06-03 17:45:51,883] Trial 155 pruned. \n",
      "[I 2024-06-03 17:46:15,066] Trial 156 finished with value: 0.3162263204921627 and parameters: {'learning_rate': 0.7819504790366923, 'n_estimators': 293}. Best is trial 123 with value: 0.32374222378531436.\n",
      "[I 2024-06-03 17:46:37,576] Trial 157 pruned. \n",
      "[I 2024-06-03 17:47:00,802] Trial 158 finished with value: 0.3172206494627764 and parameters: {'learning_rate': 0.769948631485962, 'n_estimators': 281}. Best is trial 123 with value: 0.32374222378531436.\n",
      "[I 2024-06-03 17:47:25,393] Trial 159 pruned. \n",
      "[I 2024-06-03 17:47:49,050] Trial 160 pruned. \n",
      "[I 2024-06-03 17:48:10,330] Trial 161 pruned. \n",
      "[I 2024-06-03 17:48:31,922] Trial 162 pruned. \n",
      "[I 2024-06-03 17:48:55,266] Trial 163 pruned. \n",
      "[I 2024-06-03 17:49:27,258] Trial 164 pruned. \n",
      "[I 2024-06-03 17:49:55,158] Trial 165 pruned. \n",
      "[I 2024-06-03 17:50:16,183] Trial 166 pruned. \n",
      "[I 2024-06-03 17:50:43,323] Trial 167 pruned. \n",
      "[I 2024-06-03 17:51:03,933] Trial 168 pruned. \n",
      "[I 2024-06-03 17:51:37,671] Trial 169 pruned. \n",
      "[I 2024-06-03 17:52:10,581] Trial 170 pruned. \n",
      "[I 2024-06-03 17:52:36,087] Trial 171 pruned. \n",
      "[I 2024-06-03 17:53:01,566] Trial 172 pruned. \n",
      "[I 2024-06-03 17:53:26,327] Trial 173 pruned. \n",
      "[I 2024-06-03 17:53:52,891] Trial 174 pruned. \n",
      "[I 2024-06-03 17:54:19,823] Trial 175 pruned. \n",
      "[I 2024-06-03 17:54:48,527] Trial 176 pruned. \n",
      "[I 2024-06-03 17:55:18,510] Trial 177 pruned. \n",
      "[I 2024-06-03 17:55:42,139] Trial 178 pruned. \n",
      "[I 2024-06-03 17:56:05,866] Trial 179 pruned. \n",
      "[I 2024-06-03 17:56:35,570] Trial 180 pruned. \n",
      "[I 2024-06-03 17:57:01,839] Trial 181 finished with value: 0.3154160885097458 and parameters: {'learning_rate': 0.6887872702032126, 'n_estimators': 350}. Best is trial 123 with value: 0.32374222378531436.\n",
      "[I 2024-06-03 17:57:12,299] Trial 182 pruned. \n",
      "[I 2024-06-03 17:57:28,251] Trial 183 finished with value: 0.3218882717167368 and parameters: {'learning_rate': 0.7937285197577547, 'n_estimators': 210}. Best is trial 123 with value: 0.32374222378531436.\n",
      "[I 2024-06-03 17:57:43,725] Trial 184 finished with value: 0.3232034447626063 and parameters: {'learning_rate': 0.791714261244651, 'n_estimators': 205}. Best is trial 123 with value: 0.32374222378531436.\n",
      "[I 2024-06-03 17:58:00,627] Trial 185 finished with value: 0.3192069308557546 and parameters: {'learning_rate': 0.7909603583223429, 'n_estimators': 223}. Best is trial 123 with value: 0.32374222378531436.\n",
      "[I 2024-06-03 17:58:16,991] Trial 186 pruned. \n",
      "[I 2024-06-03 17:58:34,424] Trial 187 finished with value: 0.3179530985544982 and parameters: {'learning_rate': 0.7739959556741567, 'n_estimators': 212}. Best is trial 123 with value: 0.32374222378531436.\n",
      "[I 2024-06-03 17:58:52,568] Trial 188 pruned. \n",
      "[I 2024-06-03 17:59:10,516] Trial 189 pruned. \n",
      "[I 2024-06-03 17:59:26,876] Trial 190 finished with value: 0.31960198480181756 and parameters: {'learning_rate': 0.8070534458271094, 'n_estimators': 204}. Best is trial 123 with value: 0.32374222378531436.\n",
      "[I 2024-06-03 17:59:44,490] Trial 191 finished with value: 0.3247899139386944 and parameters: {'learning_rate': 0.8033813433130741, 'n_estimators': 217}. Best is trial 191 with value: 0.3247899139386944.\n",
      "[I 2024-06-03 17:59:59,482] Trial 192 pruned. \n",
      "[I 2024-06-03 18:00:17,412] Trial 193 finished with value: 0.3157770759384339 and parameters: {'learning_rate': 0.7918120476033199, 'n_estimators': 214}. Best is trial 191 with value: 0.3247899139386944.\n",
      "[I 2024-06-03 18:00:34,111] Trial 194 pruned. \n",
      "[I 2024-06-03 18:00:52,014] Trial 195 pruned. \n",
      "[I 2024-06-03 18:01:08,093] Trial 196 pruned. \n",
      "[I 2024-06-03 18:01:25,697] Trial 197 finished with value: 0.3203319449247915 and parameters: {'learning_rate': 0.7893695089935892, 'n_estimators': 220}. Best is trial 191 with value: 0.3247899139386944.\n",
      "[I 2024-06-03 18:01:42,457] Trial 198 pruned. \n",
      "[I 2024-06-03 18:02:00,381] Trial 199 pruned. \n",
      "[I 2024-06-03 18:02:16,279] Trial 200 pruned. \n",
      "[I 2024-06-03 18:02:32,762] Trial 201 pruned. \n",
      "[I 2024-06-03 18:02:51,822] Trial 202 finished with value: 0.3175152413298859 and parameters: {'learning_rate': 0.7865709638663605, 'n_estimators': 235}. Best is trial 191 with value: 0.3247899139386944.\n",
      "[I 2024-06-03 18:03:08,415] Trial 203 pruned. \n",
      "[I 2024-06-03 18:03:27,605] Trial 204 pruned. \n",
      "[I 2024-06-03 18:03:45,660] Trial 205 pruned. \n",
      "[I 2024-06-03 18:04:02,807] Trial 206 pruned. \n",
      "[I 2024-06-03 18:04:18,551] Trial 207 pruned. \n",
      "[I 2024-06-03 18:04:36,449] Trial 208 pruned. \n",
      "[I 2024-06-03 18:04:52,700] Trial 209 pruned. \n",
      "[I 2024-06-03 18:05:11,236] Trial 210 finished with value: 0.31676864064786153 and parameters: {'learning_rate': 0.7872679683721993, 'n_estimators': 247}. Best is trial 191 with value: 0.3247899139386944.\n",
      "[I 2024-06-03 18:05:29,608] Trial 211 pruned. \n",
      "[I 2024-06-03 18:05:46,736] Trial 212 pruned. \n",
      "[I 2024-06-03 18:06:06,331] Trial 213 pruned. \n",
      "[I 2024-06-03 18:06:21,930] Trial 214 pruned. \n",
      "[I 2024-06-03 18:06:38,632] Trial 215 pruned. \n",
      "[I 2024-06-03 18:06:56,976] Trial 216 pruned. \n",
      "[I 2024-06-03 18:07:16,026] Trial 217 finished with value: 0.3175116381146489 and parameters: {'learning_rate': 0.8458604542782466, 'n_estimators': 253}. Best is trial 191 with value: 0.3247899139386944.\n",
      "[I 2024-06-03 18:07:34,848] Trial 218 pruned. \n",
      "[I 2024-06-03 18:07:52,899] Trial 219 pruned. \n",
      "[I 2024-06-03 18:08:12,057] Trial 220 pruned. \n",
      "[I 2024-06-03 18:08:28,585] Trial 221 pruned. \n",
      "[I 2024-06-03 18:08:49,068] Trial 222 pruned. \n",
      "[I 2024-06-03 18:09:07,153] Trial 223 finished with value: 0.3183817589033535 and parameters: {'learning_rate': 0.8115005050134741, 'n_estimators': 233}. Best is trial 191 with value: 0.3247899139386944.\n",
      "[I 2024-06-03 18:09:26,235] Trial 224 pruned. \n",
      "[I 2024-06-03 18:09:43,856] Trial 225 finished with value: 0.31822918464766137 and parameters: {'learning_rate': 0.7793861334863175, 'n_estimators': 221}. Best is trial 191 with value: 0.3247899139386944.\n",
      "[I 2024-06-03 18:10:02,395] Trial 226 pruned. \n",
      "[I 2024-06-03 18:10:17,425] Trial 227 pruned. \n",
      "[I 2024-06-03 18:10:35,497] Trial 228 finished with value: 0.3188914282704384 and parameters: {'learning_rate': 0.8194560233500572, 'n_estimators': 236}. Best is trial 191 with value: 0.3247899139386944.\n",
      "[I 2024-06-03 18:10:52,874] Trial 229 finished with value: 0.3169309712611971 and parameters: {'learning_rate': 0.8160814149252096, 'n_estimators': 202}. Best is trial 191 with value: 0.3247899139386944.\n",
      "[I 2024-06-03 18:11:12,307] Trial 230 pruned. \n",
      "[I 2024-06-03 18:11:28,281] Trial 231 pruned. \n",
      "[I 2024-06-03 18:11:46,183] Trial 232 pruned. \n",
      "[I 2024-06-03 18:12:03,835] Trial 233 pruned. \n",
      "[I 2024-06-03 18:12:18,141] Trial 234 pruned. \n",
      "[I 2024-06-03 18:12:35,240] Trial 235 pruned. \n",
      "[I 2024-06-03 18:12:54,782] Trial 236 pruned. \n",
      "[I 2024-06-03 18:13:13,305] Trial 237 pruned. \n",
      "[I 2024-06-03 18:13:30,455] Trial 238 pruned. \n",
      "[I 2024-06-03 18:13:46,516] Trial 239 pruned. \n",
      "[I 2024-06-03 18:14:08,154] Trial 240 pruned. \n",
      "[I 2024-06-03 18:14:28,340] Trial 241 pruned. \n",
      "[I 2024-06-03 18:14:48,685] Trial 242 finished with value: 0.3190232941222161 and parameters: {'learning_rate': 0.7953068590995959, 'n_estimators': 242}. Best is trial 191 with value: 0.3247899139386944.\n",
      "[I 2024-06-03 18:15:07,579] Trial 243 pruned. \n",
      "[I 2024-06-03 18:15:26,174] Trial 244 pruned. \n",
      "[I 2024-06-03 18:15:42,481] Trial 245 pruned. \n",
      "[I 2024-06-03 18:16:00,852] Trial 246 pruned. \n",
      "[I 2024-06-03 18:16:22,418] Trial 247 pruned. \n",
      "[I 2024-06-03 18:16:40,700] Trial 248 pruned. \n",
      "[I 2024-06-03 18:17:01,244] Trial 249 pruned. \n",
      "[I 2024-06-03 18:17:18,162] Trial 250 pruned. \n",
      "[I 2024-06-03 18:17:37,437] Trial 251 pruned. \n",
      "[I 2024-06-03 18:17:56,105] Trial 252 pruned. \n",
      "[I 2024-06-03 18:18:15,785] Trial 253 pruned. \n",
      "[I 2024-06-03 18:18:33,614] Trial 254 finished with value: 0.3166332037488958 and parameters: {'learning_rate': 0.7950921045055335, 'n_estimators': 220}. Best is trial 191 with value: 0.3247899139386944.\n",
      "[I 2024-06-03 18:18:51,485] Trial 255 finished with value: 0.3172839089625007 and parameters: {'learning_rate': 0.833732263124741, 'n_estimators': 209}. Best is trial 191 with value: 0.3247899139386944.\n",
      "[I 2024-06-03 18:19:16,425] Trial 256 pruned. \n",
      "[I 2024-06-03 18:19:35,953] Trial 257 pruned. \n",
      "[I 2024-06-03 18:19:57,611] Trial 258 pruned. \n",
      "[I 2024-06-03 18:20:14,138] Trial 259 pruned. \n",
      "[I 2024-06-03 18:20:32,065] Trial 260 finished with value: 0.3174926704869665 and parameters: {'learning_rate': 0.8327899978185133, 'n_estimators': 223}. Best is trial 191 with value: 0.3247899139386944.\n",
      "[I 2024-06-03 18:20:49,494] Trial 261 pruned. \n",
      "[I 2024-06-03 18:21:07,444] Trial 262 pruned. \n",
      "[I 2024-06-03 18:21:25,431] Trial 263 pruned. \n",
      "[I 2024-06-03 18:21:44,535] Trial 264 pruned. \n",
      "[I 2024-06-03 18:22:00,920] Trial 265 finished with value: 0.31905668221516853 and parameters: {'learning_rate': 0.8027289048495797, 'n_estimators': 205}. Best is trial 191 with value: 0.3247899139386944.\n",
      "[I 2024-06-03 18:22:17,120] Trial 266 pruned. \n",
      "[I 2024-06-03 18:22:33,702] Trial 267 pruned. \n",
      "[I 2024-06-03 18:22:49,068] Trial 268 pruned. \n",
      "[I 2024-06-03 18:23:07,361] Trial 269 pruned. \n",
      "[I 2024-06-03 18:23:24,689] Trial 270 pruned. \n",
      "[I 2024-06-03 18:23:44,803] Trial 271 pruned. \n",
      "[I 2024-06-03 18:24:01,882] Trial 272 pruned. \n",
      "[I 2024-06-03 18:24:18,042] Trial 273 finished with value: 0.3193697218570767 and parameters: {'learning_rate': 0.828733825249382, 'n_estimators': 199}. Best is trial 191 with value: 0.3247899139386944.\n",
      "[I 2024-06-03 18:24:35,217] Trial 274 pruned. \n",
      "[I 2024-06-03 18:24:52,010] Trial 275 pruned. \n",
      "[I 2024-06-03 18:25:11,250] Trial 276 pruned. \n",
      "[I 2024-06-03 18:25:26,792] Trial 277 pruned. \n",
      "[I 2024-06-03 18:25:41,931] Trial 278 pruned. \n",
      "[I 2024-06-03 18:25:58,186] Trial 279 pruned. \n",
      "[I 2024-06-03 18:26:13,212] Trial 280 pruned. \n",
      "[I 2024-06-03 18:26:32,119] Trial 281 pruned. \n",
      "[I 2024-06-03 18:26:50,847] Trial 282 pruned. \n",
      "[I 2024-06-03 18:27:08,349] Trial 283 pruned. \n",
      "[I 2024-06-03 18:27:26,904] Trial 284 pruned. \n",
      "[I 2024-06-03 18:27:46,486] Trial 285 pruned. \n",
      "[I 2024-06-03 18:28:15,614] Trial 286 finished with value: 0.3185759527108404 and parameters: {'learning_rate': 0.8440244467568468, 'n_estimators': 363}. Best is trial 191 with value: 0.3247899139386944.\n",
      "[I 2024-06-03 18:28:45,248] Trial 287 pruned. \n",
      "[I 2024-06-03 18:29:14,551] Trial 288 pruned. \n",
      "[I 2024-06-03 18:29:43,279] Trial 289 pruned. \n",
      "[I 2024-06-03 18:30:13,725] Trial 290 pruned. \n",
      "[I 2024-06-03 18:30:42,647] Trial 291 pruned. \n",
      "[I 2024-06-03 18:31:02,130] Trial 292 pruned. \n",
      "[I 2024-06-03 18:31:26,689] Trial 293 pruned. \n",
      "[I 2024-06-03 18:31:57,293] Trial 294 pruned. \n",
      "[I 2024-06-03 18:32:13,876] Trial 295 pruned. \n",
      "[I 2024-06-03 18:32:32,283] Trial 296 pruned. \n",
      "[I 2024-06-03 18:32:51,849] Trial 297 pruned. \n",
      "[I 2024-06-03 18:33:09,280] Trial 298 pruned. \n",
      "[I 2024-06-03 18:33:27,794] Trial 299 pruned. \n",
      "[I 2024-06-03 18:33:56,016] Trial 300 finished with value: 0.31696140125269207 and parameters: {'learning_rate': 0.7605633660653179, 'n_estimators': 345}. Best is trial 191 with value: 0.3247899139386944.\n",
      "[I 2024-06-03 18:34:25,264] Trial 301 pruned. \n",
      "[I 2024-06-03 18:34:43,539] Trial 302 finished with value: 0.3190874195924692 and parameters: {'learning_rate': 0.8108380843906495, 'n_estimators': 230}. Best is trial 191 with value: 0.3247899139386944.\n",
      "[I 2024-06-03 18:35:01,333] Trial 303 pruned. \n",
      "[I 2024-06-03 18:35:19,863] Trial 304 pruned. \n",
      "[I 2024-06-03 18:35:37,241] Trial 305 pruned. \n",
      "[I 2024-06-03 18:35:52,253] Trial 306 pruned. \n",
      "[I 2024-06-03 18:36:09,724] Trial 307 pruned. \n"
     ]
    }
   ],
   "source": [
    "# hyperparemeter tuning with optuna\n",
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "     # Define hyperparameters to tune\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.08, 1.0),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'random_state': 42\n",
    "      }\n",
    "\n",
    "\n",
    "    # Create the model with trial parameters\n",
    "    model = GradientBoostingClassifier(**params)\n",
    "\n",
    "    # Define the pipeline with SMOTE and the preprocessor\n",
    "    pipeline = ImbPipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('smote', SMOTE()),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    \n",
    "   \n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(pipeline, X_train, y_train, scoring='f1', cv=skf, n_jobs=-1)\n",
    "    mean_cv_score = cv_scores.mean()\n",
    "    \n",
    "    # Report intermediate values for pruning\n",
    "    trial.report(mean_cv_score, step=0)\n",
    "    \n",
    "    if trial.should_prune():\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "    \n",
    "    # Return the mean of the cross-validation scores\n",
    "    return mean_cv_score\n",
    "\n",
    "# Set up the Optuna study\n",
    "n_trials=500\n",
    "study = optuna.create_study(direction='maximize',\n",
    "                            storage=\"sqlite:///db.sqlite3\",\n",
    "                            pruner=optuna.pruners.MedianPruner(n_startup_trials=5))\n",
    "study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(f'Best hyperparameters: {study.best_params}')\n",
    "\n",
    "# Train the final model with the best hyperparameters\n",
    "best_params = study.best_params\n",
    "best_model = GradientBoostingClassifier(\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    max_features=best_params['max_features'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63db9b3-82d4-49f9-bb39-a1937c1dfc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline with the best model\n",
    "pipeline = ImbPipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', SMOTE()),\n",
    "    ('classifier', best_model)\n",
    "])\n",
    "\n",
    "# Train the model on the full training set\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846472ec-9eb6-469e-93d2-72789586025a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get the parameters for tuning based on best model\n",
    "# params_to_tune = models_params[best_model_name]  # Change this to the parameter grid for the chosen model\n",
    "# print(f\"Following parameters of the '{best_model_name}' model will be tuned:\\n{params_to_tune}\")\n",
    "\n",
    "# # hyperparameter tuning with GridSearchCV\n",
    "# pipeline = ImbPipeline(steps=[\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('smote', SMOTE()),\n",
    "#     ('classifier', models[best_model_name])\n",
    "# ])\n",
    "\n",
    "# grid_search = GridSearchCV(pipeline, params_to_tune, cv=skf, scoring='f1', n_jobs=-1)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print(f'Best parameters of {best_model_name} model: {grid_search.best_params_}')\n",
    "# print(f'Best CV F1 Score: {grid_search.best_score_}')\n",
    "\n",
    "# # Train the best model on the full training set with the best parameters\n",
    "# best_model = grid_search.best_estimator_\n",
    "# best_model.fit(X_train, y_train)\n",
    "\n",
    "# # Evaluate the best model on the test set\n",
    "# y_pred = best_model.predict(X_test)\n",
    "\n",
    "\n",
    "# # Output the test predictions and evaluation\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dca086-0277-40e3-a41a-02673baca7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_scores(y_target, y_predicted) -> Dict[str, Any]:\n",
    "    metric_types = [accuracy_score, balanced_accuracy_score, f1_score, roc_auc_score]\n",
    "    metric_scores_dict = dict()\n",
    "    for metric_class in metric_types:\n",
    "        metric_name = metric_class.__name__\n",
    "        metric = metric_class(y_target, y_predicted)  # initialize metric\n",
    "        metric_scores_dict[f\"{metric_name}\"] = metric\n",
    "    return metric_scores_dict\n",
    "\n",
    "metric_scores = compute_metrics_scores(y_test, y_pred)\n",
    "metric_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2bfb14-3cb6-4143-ae1e-e0c39e241047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate ROC curve and Precision-Recall curve\n",
    "false_positive_rate, true_positive_rate, _ = roc_curve(y_test, y_pred)\n",
    "auc_score = roc_auc_score(y_test, y_pred)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5daf9d0-df6a-4bf1-9a2e-6ccdde5e82af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(false_positive_rate, true_positive_rate, label=f'ROC Curve area (AUC = {auc_score:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742ea980-6afb-4380-aa26-9745fc62e875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Precision-Recall curve\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall, precision, label='Precision-Recall Curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc='lower left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea86a42-7a2e-4961-810d-a9a9431d99f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a69c90-7b3e-42f8-a508-de4e22608c70",
   "metadata": {},
   "source": [
    "#### Persist the model and preprocessor and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2dc1e6-276c-4ab2-aa5b-4e6740630999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persist the trained model and preprocessor\n",
    "joblib.dump(pipeline, 'trained_model_pipeline.pkl')\n",
    "\n",
    "# Load the model and preprocessor for future use\n",
    "loaded_pipeline = joblib.load('trained_model_pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a343075b-6232-461f-8de4-403ab186900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data   # TODO: function\n",
    "path_to_test_data = \"../data/test_file.xlsx\"\n",
    "df_test_data = pd.read_excel(path_to_test_data)\n",
    "df_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e6029b-2cb8-4f09-b2b7-41752ad32322",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_data = df_test_data.drop(features_to_remove, axis=1)\n",
    "df_test_data.query('job != \"unknown\" & education != \"unknown\" & default != \"unknown\" & housing != \"unknown\"', inplace=True)\n",
    "df_test_data.reset_index(inplace=True)\n",
    "df_test_data[\"education\"] = df_test_data[\"education\"].replace([\"basic.4y\", \"basic.6y\", \"basic.9y\"], \"education.basic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705ff9fe-b640-4e05-b23e-427eb7136f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_age = pd.cut(df_test_data[\"age\"], bins=bins_nmb, labels=age_order)\n",
    "df_test_data.insert(1, \"bins_age\", bins_age)\n",
    "# remove age column from dataframe\n",
    "df_test_data.drop(\"age\", axis=1, inplace=True)\n",
    "df_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fd53a6-e0c0-41b0-9208-29e93f9405bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding with LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df_test_data[\"contact\"] = label_encoder.fit_transform(df_test_data[\"contact\"])\n",
    "\n",
    "# encoding with binary values\n",
    "binary_mapping = {\"yes\": 1, \"no\": 0}\n",
    "columns_to_map = [\"default\", \"loan\", \"housing\"]  # no y\n",
    "for column in columns_to_map:\n",
    "    df_test_data[column] = df_test_data[column].map(binary_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5a50bc-8d41-456a-a5cb-90d0f6e62132",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c42e7d-f59a-46e2-97de-3359450c786c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and preprocessor for future use\n",
    "loaded_pipeline = joblib.load('trained_model_pipeline.pkl')\n",
    "\n",
    "# Use the loaded model to make predictions on new data\n",
    "new_predictions = loaded_pipeline.predict(df_test_data)\n",
    "print(new_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27eade0-5d10-409e-ae0c-de55e6846041",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred in y_pred:\n",
    "    if pred == 1:\n",
    "        print(f\"{y_pred.index(pred)}: {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386f346e-d0ce-405b-89ac-d571cf919cd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e26197-0ae3-4e94-bf53-cc9fb62104f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3dc478-8493-4fc8-aad2-1f16d158b3fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
